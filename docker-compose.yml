 version: '2'
 volumes:
  collected_static: {}
 services:

  # # ubertool_eco Django front-end
  # eco_django:
  #   build: ./ubertool_eco
  #   expose:
  #   - "8080"
  #   volumes:
  #   - collected_static:/src/collected_static
  #   environment:
  #   - UBERTOOL_REST_SERVER=http://nginx:7777


  # ubertool_cts Django front-end
  cts_django:
    build: ./cts_app
    image: cts-uwsgi-django:latest
    expose:
    - "8081"
    volumes:
    - collected_static:/src/collected_static
    # - .:/src  # map ubertool_cts/ to /src for updating without rebuilding images
    environment:
    - REDIS_HOSTNAME=redis
    links:
    - redis

  # Redis (message broker)
  redis:
    image: redis:latest
    hostname: redis
    # ports:
    # - "6379:6379"
    expose:
      - "6379"

  # ubertool_cts nodejs submodule
  cts_nodejs:
    build: ./cts_app/cts_nodejs
    image: cts-nodejs:latest
    expose:
      - "4000"
    environment:
      - NODEJS_HOST=cts_nodejs
      - NODEJS_PORT=4000
      - REDIS_HOSTNAME=redis
      - REDIS_HOST=redis
      - REDIS_PORT=6379
    links:
      - redis
      - worker_chemaxon
      - worker_epi
      - worker_test
      - worker_sparc
      - worker_measured

  # # Celery worker - ChemAxon calc
  worker_chemaxon:
    build: ./cts_app/cts_celery
    image: cts-celery:latest
    command: celery worker -A tasks -Q chemaxon -l info -n chemaxon_worker -c 2
    # command: bash -c "sleep 3 && celery -A tasks worker -Q chemaxon --loglevel=info --concurrency=1 -n chemaxon_worker"
    links:
    - redis
    environment:
    - REDIS_HOSTNAME=redis


  # # Celery worker - EPI Suite calc
  worker_epi:
    build: ./cts_app/cts_celery
    image: cts-celery:latest
    # image: cts-celery:epi
    command: celery worker -A tasks -Q epi -l info -n epi_worker -c 1
    links:
    - redis
    environment:
    - REDIS_HOSTNAME=redis
    # extra_hosts:
    #   - "localhost:10.0.2.2"

  # # Celery worker - TEST calc
  worker_test:
    build: ./cts_app/cts_celery
    image: cts-celery:latest
    # image: cts-celery:test
    command: celery worker -A tasks -Q test -l info -n test_worker -c 1
    links:
    - redis
    environment:
    - REDIS_HOSTNAME=redis

  # # Celery worker - SPARC calc
  worker_sparc:
    build: ./cts_app/cts_celery
    image: cts-celery:latest
    # image: cts-celery:sparc
    command: celery worker -A tasks -Q sparc -l info -n sparc_worker -c 1
    links:
    - redis
    environment:
    - REDIS_HOSTNAME=redis

  # # Celery worker - Measured (EPI) calc
  worker_measured:
    build: ./cts_app/cts_celery
    image: cts-celery:latest
    # image: cts-celery:measured
    command: celery worker -A tasks -Q measured -l info -n measured_worker -c 1
    links:
    - redis
    environment:
    - REDIS_HOSTNAME=redis


  # # ubertool_ecorest Flask back-end
  # ecorest:
  #   build: ./ubertool_ecorest
  #   expose:
  #   - "7777"

  qed_nginx:
    restart: always
    build: ./qed_nginx
    ports:
    - "80:80"
    - "443:443"
    - "7777:7777"
    links:  # Same as depends_on eco_django, but also sets the hostname at which this service can reach the linked service
    # - eco_django:uwsgi_django  # Nginx.conf can reference "eco_django" service with the hostname 'uwsgi_django' or 'eco_django'
    # - ecorest:uwsgi_flask      # Nginx.conf can reference "ecorest" service with the hostname 'uwsgi_flask' or 'ecorest'
    - cts_django:uwsgi         # Nginx.conf can reference "cts_django" service with the hostname 'uwsgi' or 'cts_django'
    volumes:
    - /var/www/nginx/certs:/etc/nginx/qed
    volumes_from:
    # - eco_django:ro  # Mount all volumes from "eco_django" to NGINX, so it can access the collected static files (ro = read-only)
    - cts_django:ro  # Mount all volumes from "cts_django" to NGINX, so it can access the collected static files
